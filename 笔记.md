# 2025-05-03

## Session共享

当登录管理采用session存储时，用户在登录时，会在该用户登录的服务器上创建一个Session，用户会将该session的JSESSIONID存储在前端，以便下次访问服务时，判断登录态。



先假设有两个服务器A，B分别提供两种服务。用户只在服务器A上登录，如何让用户免登陆访问服务器B。



> 拓展：JSESSIONID一般存储在Cookie中，而Cookie是有作用范围的。
> Cookie的作用域**常见**的有两个：domain和path。domain指定了哪些主机可以接受本cookie，path指定了当前主机下，哪些路径可以接受cookie。
>
> 这就导致了一个小问题。在本地开发调试时，服务器A可能是部署在localhost:8080, aplication context 为 /api, 服务器B可能部署在localhost:8081, application context也为/api。这就会导致，登录这两个服务器，所获得的cookie的domain和path相同。用户在浏览器中登录服务器A后，获得了SessionID，然后再去登录服务器B，那么，前一个获得的SessionID会被覆盖掉,导致丢失服务器A的登录态。





答案：共享存储。让服务器A，B能够访问到共有的登录态管理信息。



共享存储方案： 1.Redis 2. Mysql 3.文件服务器  等等方案

这里采用Redis，为什么？

①用户信息的读取/是否登录的判断  **极其频繁** 。Redis基于内存，读写性能更高。简单数据，读写QPS能够达到5w-10w。

## 实现方法

前提：确保本机或云端安装了redis。

1. 项目中引入redis依赖和spring session redis implement依赖。

   ```xml
   <!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-data-redis -->
   <dependency>
       <groupId>org.springframework.boot</groupId>
       <artifactId>spring-boot-starter-data-redis</artifactId>
       <version>2.6.4</version>
   </dependency>
   
   <!-- 版本号最好与spring boot框架的版本一致-->
   
   <!-- https://mvnrepository.com/artifact/org.springframework.session/spring-session-data-redis -->
   <dependency>
       <groupId>org.springframework.session</groupId>
       <artifactId>spring-session-data-redis</artifactId>
       <version>2.6.4</version>
   </dependency>
   ```

2. 配置session默认从redis当中读取。（由于框架已经提供了这个功能，所以看似复杂，实际简单）

   ```yaml
     # session 失效时间
     session:
       timeout: 86400
       store-type: redis  # 从redis当中读取
       # store-type: none # 默认从本机服务器session context读取
     # redis 配置
     redis:
       port: 6379
       database: 0
       host: localhost
   ```

   使用共享Session来实现分布式登录非常简单，也较为推荐。也可以采取jwt来实现，但是jwt不是太适用于用户认证，可以实现相同的功能，但不推荐。

   [[jwt优缺\]]: （https://zhuanlan.zhihu.com/p/108999941）

   ## 数据导入

   本地开发时，数据量较少。需要手动导入数据模拟实际场景。

   

   导入方法：

   1. 可视化界面导入数据。比如通过navicat, workbench等导入Excel,csv文件数据。
   2. 通过sql语句导入数据。适用于少量数据。
   3. 利用程序来导入数据。（可控性最高）

   ### 利用程序导入批量数据

   在使用mybatis框架的mapper进行insert操作时，该操作会进行：创建sqlsession（创建连接）， 执行sql语句， 关闭sqlsession（释放连接）。如果每次插入一条数据，那么创建和释放连接的过程极其耗时。所以最好采用批量插入。而批量插入已由MyBatis-plus提供(比如UserService通常会继承IService， IService提供了saveBatch方法)。

   ### 编写一次性代码

   导入数据通常是一次性的。可以在单元测试中对测试类打上@SpringBootTest注解后，编写导入数据的代码。（缺点：单元测试会在每次项目打包时自动执行一次，这意味着会再执行一遍插入数据的代码。）

   

   > 为了使用Mybatis框架，编写的一次性代码必须要能够使用spring的bean。如果单独写一个类，并在该类中添加main方法执行，而不添加其他注解，那么无法实现依赖注入。

   下面是批量插入数据的代码。需要注意，由于数据库id为主键，其具有唯一性约束。如果单纯运行下面代码，妄图依靠数据库自增来插入数据，可能会遇到报错，**目前还没弄明白原因**。

   
   
   > 2025-05-04：原因弄清楚了。mybatis会在插入数据后，自动更新插入对象。对于userMapper.insert()方法，传入对象User user作为插入对象，如果user的id为null，那么在插入后，user会被更新为其在数据库中的主键值。在下面的代码中，userList中的user对象是同一个（因为它们具有相同的引用。）
   >
   >
   > **将下面这段错误代码改动一下，以使得能够插入多条数据。**将new User以及初始化部分属性的代码放到for循环中即可。
   
   ```java
   package com.yupi.usercenter;
   
   import java.util.LinkedList;
   import java.util.List;
   
   import com.yupi.usercenter.mapper.UserMapper;
   import com.yupi.usercenter.model.domain.User;
   import com.yupi.usercenter.service.UserService;
   import org.junit.jupiter.api.Test;
   import org.springframework.boot.test.context.SpringBootTest;
   import org.springframework.util.StopWatch;
   
   import javax.annotation.Resource;
   
   @SpringBootTest
   public class ImportDataTest {
   
       @Resource
       UserService userService;
   
       @Resource
       UserMapper userMapper;
   
       final long INSERT_NUM = 1000L;
   
       @Test
       public void importData(){
           User user = new User();
           user.setId(null);
           user.setUsername("tlm");
           user.setUserAccount("123456789");
           user.setAvatarUrl("https://tse2-mm.cn.bing.net/th/id/OIP-C.cn_mIqJN0Td_0Ono0xMEsQHaLL?rs=1&pid=ImgDetMain");
           user.setGender(0);
           user.setUserPassword("12345678");
           user.setPhone("13432532");
           user.setEmail("123@qq.com");
           user.setUserStatus(0);
           user.setUserRole(0);
           user.setPlanetCode("555555555");
           user.setTags("[]");
   
           StopWatch stopWatch = new StopWatch();
   
           stopWatch.start();
   
           List<User> userList = new LinkedList<User>();
   
           for (long i = 0; i < INSERT_NUM; i++) {
               userList.add(user);
           }
           userService.saveBatch(userList, 10);
   
           stopWatch.stop();
           System.out.println(stopWatch.getTotalTimeMillis());
       }
   }
   
   ```
   
   ### 并发编程
   
   上面插入数据的代码是线性的(for循环)。如何并发执行。
   
   
   
   使用CompletableFuture来实现。CompletableFuture是异步，非阻塞并发编程API。
   
   
   
   在编写并发代码时需要注意：线程执行顺序不可知；不要使用非并发的集合类。
   
   ```java
       @Test
       public void asyncImportData(){
           StopWatch stopWatch = new StopWatch();
   
           stopWatch.start();
   
           List<User> userList = new LinkedList<User>();
           List<CompletableFuture<Void>> futureList = new ArrayList<>();
   
           for(int j = 0; j < 10; j++){
               List<User> tempUserList = new LinkedList<>();
               while(true){
                   User user = new User();
                   user.setId(null);
                   user.setUsername("tlm");
                   user.setUserAccount("123456789");
                   user.setAvatarUrl("https://tse2-mm.cn.bing.net/th/id/OIP-C.cn_mIqJN0Td_0Ono0xMEsQHaLL?rs=1&pid=ImgDetMain");
                   user.setGender(0);
                   user.setUserPassword("12345678");
                   user.setPhone("13432532");
                   user.setEmail("123@qq.com");
                   user.setUserStatus(0);
                   user.setUserRole(0);
                   user.setPlanetCode("555555555");
                   user.setTags("[]");
   
                   tempUserList.add(user);
                   if (tempUserList.size() % 1000 == 0){
                       break;
                   }
               }
   
               CompletableFuture<Void> voidCompletableFuture = CompletableFuture.runAsync(() -> {
                   userService.saveBatch(tempUserList, 1000);
               });
               futureList.add(voidCompletableFuture);
           }
   
   
   
           CompletableFuture.allOf(futureList.toArray(new CompletableFuture[]{})).join();
   
           stopWatch.stop();
           System.out.println(stopWatch.getTotalTimeMillis());
       }
   ```
   
   对于CompletableFuture，如果没有为其指定线程池，则默认使用java的ForkJoinPool线程池，该线程池的容量与主机逻辑处理器一致。可以自己定义线程池，传递给CompletableFuture来完成并发任务。
   
   
   
   > 通常：
   >
   > 对于计算密集型任务： 线程池容量定义为 = CPU核数 - 1。 这里的1，是留给主线程的。
   >
   > 对于IO密集型任务：线程池的容量可以  > CPU核数。
   
   ## 分页查询
   
   用户查询数据，后端返回数据。如果后端返回的数据过多，那么前端渲染的压力就会升高。通常会采用分页查询方式。
   
   1. 引入MyBatis-Plus分页查询配置类。
   
   ```java
   @Configuration
   @MapperScan("scan.your.mapper.package")
   public class MybatisPlusConfig {
   
       /**
        * 添加分页插件
        */
       @Bean
       public MybatisPlusInterceptor mybatisPlusInterceptor() {
           MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
           interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); // 如果配置多个插件, 切记分页最后添加
           // 如果有多数据源可以不配具体类型, 否则都建议配上具体的 DbType
           return interceptor;
       }
   }
   ```
   
   2. 使用分页查询:
   
      ```java
      @GetMapping("recommend")
          public BaseResponse<Page<User>> recommendUsers(int pageSize, int pageNum, HttpServletRequest request){
              QueryWrapper<User> wrapper = new QueryWrapper<>();
              Page<User> userList = userService.page(new Page<>(pageNum, pageSize), wrapper);
              return ResultUtils.success(userList);
          }
      
      ```
   
   ## 数据查询慢
   
   通常，当查询速度慢时，会采取缓存。
   
   就缓存位置而言，缓存分为两种：本地缓存和分布式缓存。本地缓存就是将数据存储在本地机器上。分布式缓存就是将数据存储在远程机器上。
   
   * 常见的缓存框架：
   
     * Redis(分布式缓存)
   
     * memcached(分布式缓存)
   
     * Etcd（云原生架构的一个分布式存储，主要存储配置,扩容能力强）
   
       ---------------------------------------------------
   
     * EhCache(数据库缓存框架, 单机 )
   
     * Caffeine（本地缓存框架)
   
     * Google Guava(Caffeine的前身)
   
     * 本地缓存（java内存， 比如Map， 虽然这不是框架，但也提一下）
   
   
   
   ## Redis
   
   Redis是一个 K / V 存储系统。
   
   其常见数据结构如下：
   
   * string : `name : "tlm"`
   * list: `names : ["a", "b", "c", "c"]`
   * set: `names : ("a", "b", "c")`
   * hash: `names : { "1号" : "tlm", "2号": "shr"}`
   * zset: `("a" - 3, "b"- 4, "c" - 7)`, 与set相比，每个元素多了一个分数值。
   
   
   
   ### 如何在java程序中操作Redis
   
   三种方式：**Spring Data Redis(推荐)**, Jedis, Redission。
   
   这里只介绍Spring Data Redis.
   
   1. 导入依赖并配置：
   
      ```java
      <!-- https://mvnrepository.com/artifact/org.springframework.data/spring-data-redis -->
      <dependency>
          <groupId>org.springframework.data</groupId>
          <artifactId>spring-data-redis</artifactId>
          <version>2.6.4</version>
      </dependency>
      ```
   
      ```yml
      spring:
        # redis 配置
        redis:
          port: 6379
          database: 0
          host: localhost
      ```
   
      
   
   2. 利用RedisTemplate获取操作Redis的对象。在下面这段代码中，需要注意，如果RedisTemplate没有指定序列化器，则默认使用JDK的序列化器。这也是下面这段代码存到redis中，键和值都存在乱码的原因。
   
      ```java
      @SpringBootTest
      public class RedisTest {
      
          @Resource(name = "getRedisTemplate")
          private RedisTemplate redisTemplate;
      
          @Test
          public void testRedis(){
      
              ValueOperations valueOperations = redisTemplate.opsForValue();
      
              valueOperations.set("ok", "tlm");
              valueOperations.set("test", 1);
              valueOperations.set("testtest", 1.0);
              User user = new User();
              user.setId(1L);
              user.setUsername("tlm");
      
              valueOperations.set("object", user);
      
              Object stringValue = valueOperations.get("ok");
              Assert.assertTrue("tlm".equals((String) stringValue));
          }
      }
      ```
   
   3. 自定义序列化器（可选）: 由于RedisTemplate默认使用jdk的序列化器，不便于我们观察。所以需要自定义序列化器。**下面需要注意：RedisTemplate自动注入时，使用的是@AutoWired注解，试试@Resource注解可以吗？ 答：实际上不可以，因为框架也有提供RedisTempate，使用@Resource会导致冲突。程序能够运行，但是没有我们想要的结果（即，和没有自定义前相比， 没有任何变化)。。。那使用@Resource就不行吗？当然可以，指定名称就行，本质是解决冲突。@Bean所创造的bean的名称为方法名。@Resource注入时，指定注解属性name = "getRedisTemplate"即可。**
   
      ```java
      package com.yupi.usercenter.config;
      
      import org.springframework.boot.autoconfigure.cache.CacheProperties;
      import org.springframework.context.annotation.Bean;
      import org.springframework.context.annotation.Configuration;
      import org.springframework.context.annotation.Primary;
      import org.springframework.data.redis.connection.RedisConnectionFactory;
      import org.springframework.data.redis.core.RedisTemplate;
      import org.springframework.data.redis.serializer.RedisSerializer;
      
      @Configuration
      public class RedisConfig {
      
          @Bean
          RedisTemplate<String, Object> getRedisTemplate(RedisConnectionFactory factory){
              RedisTemplate<String, Object> redisTemplate = new RedisTemplate();
              redisTemplate.setConnectionFactory(factory);
              redisTemplate.setKeySerializer(RedisSerializer.string());
              System.out.println("Config 中的Redistemplate:" + redisTemplate);
              return redisTemplate;
          }
      }
      
      
      ```
   
      
   
   ### 设计缓存的key
   
   在实际开发中，有可能为了节省成本，多个项目共用一个redis，这就要求我们能够区分不同项目的缓存，避免冲突。
   
   常见的设计方法： SystemId:ModuleId:FuncName:Options
   
   具体示例: friendMatch:user:recommend:userId
   
   注意：**Redis内存不能无限增加，一定要设置过期时间。**当redis内存达到限制时，会触发内置的淘汰策略。部分key/value会被清理掉。
   
   
   
   ## 缓存预热
   
   虽然使用了缓存技术，但是在业务逻辑上，缓存需要用户第一次访问来触发。这就会导致用户第一访问会比较慢（因为此时还没有缓存）。
   
   缓存预热就是在用户访问前，提前将会被访问的数据进行缓存。
   
   *缓存预热的优缺点*：优点：能够解决用户第一次访问过慢的问题。缺点：1. 增加开发成本（需要额外的逻辑与设计）2. 预热实际和时间如果错了，会导致缓存的数据不一致。3. 需要占用额外的空间。
   
   怎么进行缓存预热？：1. 定时任务触发 2. 模拟触发（手动触发），较为少见，但是偶尔也会有，比如双十一，京东，淘宝等平台。
   
   > tips: **分析优缺点时，要打开思路，从软件工程生命周期的全流程去考虑。** 
   
   **使用缓存预热时需要注意的问题**:
   
   1. 缓存的数据需要有意义
   2. 缓存的数据不应该过大，要给其他缓存预留空间
   3. 缓存数据的更新周期
   
   ### 使用定时任务进行缓存预热
   
   常用的定时任务框架：
   
   Spring schedular
   
   Quartz
   
   XXL-job(分布式定时任务框架)
   
   -----
   
   主要介绍Spring Schedular的使用。
   
   1. 首先需要在启动类上打上@EnableScheduling注解。
   
   2. 定义一个新的类(通常该类放在一个名为job的package中，依据团队习惯而定)，将其声明为Bean，然后在该类的方法上打上@Scheduled注解，并且指定cron表达式，将该方法标识为一个定时任务。
   
      ```java
      package com.yupi.usercenter.job;
      
      import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
      import com.yupi.usercenter.model.domain.User;
      import com.yupi.usercenter.service.UserService;
      import lombok.extern.slf4j.Slf4j;
      import org.springframework.data.redis.core.RedisTemplate;
      import org.springframework.data.redis.core.ValueOperations;
      import org.springframework.scheduling.annotation.Scheduled;
      import org.springframework.stereotype.Component;
      
      import javax.annotation.Resource;
      import java.util.Arrays;
      import java.util.List;
      import java.util.concurrent.TimeUnit;
      
      @Component
      @Slf4j
      public class PreCacheJob {
      
          @Resource
          private UserService userService;
      
          @Resource(name = "getRedisTemplate")
          private RedisTemplate redisTemplate;
      
          private List<Long> mainUserList = Arrays.asList(1L);
      
          @Scheduled(cron = "0 10 20 * * *")
          public void preCacheUserRecommend(){
              ValueOperations valueOperations = redisTemplate.opsForValue();
              String keyTemplate = "friendMatch:user:recommend:%s";
      
              for (Long aLong : mainUserList) {
                  String key = String.format(keyTemplate, aLong);
                  User user = new User();
                  user.setId(aLong);
                  Page<User> recommendUser = userService.getRecommendUser(user, 1, 8);
      
                  try {
                      valueOperations.set(key, recommendUser, 1, TimeUnit.DAYS);
                  } catch (Exception e) {
                      log.error("PreCacheJob had failed!!!", e);
                  }
      
              }
      
          }
      
      }
      
      ```
   
   
   # 2025-05-06

* 场景示例
  对于缓存预热问题，前面采取的是“定时任务”的解决方案。在分布式场景下，同一套代码会在多台服务器上部署，这就导致，这多台服务器都会在同一时刻发送相同的请求，去更新redis上缓存的内容，实际上，只需要一台服务器发送请求就可以了。

* 如果不采取措施，让多台服务器都执行定时任务，会造成什么不好的后果？

  * 资源浪费。执行一次定时任务即可，却发送多次任务请求。
  * 如果定时任务是增量插入任务，会导致数据库出现冗余数据。

* 如何解决这个问题？

  1. 将定时任务从项目中抽取出来，单独作为一个服务在单个机器上部署。缺点：增加开发成本。
  2. 写死配置，每个服务器都执行定时任务，但在实际执行前先判断，是否是指定服务器IP，如果是，则执行，否则直接退出定时任务。缺点：在实际部署中，常使用docker容器技术，服务器的IP可能不可知，甚至会动态变化。
  3. 动态配置（代码无需重启）。但是只有IP符合配置的机器执行定时任务。
     * 数据库
     * Redis
     * 配置中心(Nacos, Apollo, Spring Cloud Config)

  以上三种方法，都能解决问题。但是都会面临**单点故障问题**。服务器数量较少时，采用上面的方法较为适合。

  ## 锁

  锁是为了解决有限资源分配给多个主体问题而产生的。

  在Java中，对于有限资源加锁可以采用synchronized关键字。对于加上了该关键字的作用域，同一时间，只有一个线程能够执行。

  ## 分布式锁

  在Java中，synchronized关键字加的锁，可以称其为**本地锁**， 因为，它只对本进程中的线程生效。在分布式场景中，可能会有多台服务器同时访问同一个资源。这个时候，java提供的本地锁就不足以解决有限资源分配给多个主体的问题。

  分布式锁。分布式就是为了解决本地锁的缺点而诞生的。只有抢到锁的服务器才会执行业务逻辑。坏处：增加成本（实际并不多）， 好处：不用手动配置，多少个服务器都一样。	

  * 锁的核心思想：先来的人把资源打上自己的唯一标识，后来的人发现资源已被标识，就会继续等待。先来的那个人使用完资源后，会释放资源，即清空标识。
  * 如何实现？
    * MySQL数据库：select for update 行级锁(最简单，成本低)，或者乐观锁（自己写判断逻辑，这个只提一下）。
    * Redis实现：支持setnx，lua脚本实现原子操作。内存数据库，读写速度快。setnx与set的表现形式上相同，都是设置一个k/v，但是setnx对于已经设置过的k/v会直接返回(nil， 也就是false)。
    * Zookeeper实现(不推荐利用Zookeeper实现分布式锁)：较少使用。

### 在Redis中实现分布式锁需要注意的问题

1. 用完锁一定要释放。

2. 锁一定要设置过期时间。

3. 如果方法执行时间过长，锁已经提前过期了。
   会导致的问题：

   1. 假如服务器A抢到锁后，需要执行定时任务40s，而锁30s过期，那么锁过期后，被服务器B占领，而A随后执行完任务释放锁。连锁效应：同一时间多个服务同时在执行。怎么解决？根据标识，服务器A在释放锁时，检查一下标识是否是自己打上的标识。如果不是，则不释放。

   解决方法：**续期**（看门狗机制）

   可以通过AOP，或者一个Listener来监听执行中的任务，如果到了指定时间还未执行完，那就续期。

   ```java
   boolean end = false;
   new Thread(()->{
       if (!end) {
           续期;
       }
   })
   end = true;
   ```

   

4. 释放锁的时候，需要先判断锁是否是自己的标识，然后再去删除。假如服务器A释放锁时，判断的确是自己的标识，但是就在完成这一判断的那一刻，锁过期了，这时候，服务器B突然抢占了锁。这就会导致服务器A释放掉服务器B的锁。
   解决方法： Redis+lua脚本实现。

   ```java
   // 下面这段代码需要是原子操作才能避免上面的问题
   if (get lock == A){
       // B抢占了锁
       del lock;
   }
   ```

# 2025-05-07

## 使用Redisson实现分布式锁

什么是Redisson？
Redisson是用来操作ValKey和Redis的Java客户端以及实时数据平台。它提供一系列了对Valkey和Redis的数据操作的抽象，使得用户只需要关心数据模型和应用逻辑。在Java中，可以像操作原生集合类一样操作，Redisson提供的类。

* 使用流程：

  1. 导入依赖：

     * 方法一：引入Spring Boot Starter，让spingboot来整合redisson并提供redisson客户端。（不推荐，因为Redisson版本迭代太快了，容易出问题。可以用，也非常方便，如果能正常运行的话。）
     * 方法二：只引入Redisson，然后自己配置Redisson客户端。(使用)

     ```java
                 <dependency>
                     <groupId>org.redisson</groupId>
                     <artifactId>redisson-spring-data-26</artifactId>
                     <version>3.17.0</version>
                 </dependency>
     ```

  2. 配置Redisson客户端。具体为创建一个配置类，并在该方法中创建一个Redisson客户端的类交给容器管理，在需要的时候通过依赖注入使用。

     ```java
     @Configuration
     @ConfigurationProperties(prefix = "spring.redis")
     @Data
     public class RedissonConfig {
     
     // 需要再application.xml文件中配置相关属性，或者写死在代码中
         private String host;
         private String port;
     
         private Integer database;
     
         @Bean(destroyMethod="shutdown")
         RedissonClient redisson() throws IOException {
             Config config = new Config();
             config.useSingleServer().setAddress(String.format("redis://%s:%s", host, port)).setDatabase(database);
     
             return Redisson.create(config);
         }
     
     }
     ```

     3. 对于需要使用到分布式锁的程序代码进行改造。
     
        ```java
        @Component
        @Slf4j
        public class PreCacheJob {
        
            @Resource
            private UserService userService;
        
            @Resource(name = "getRedisTemplate")
            private RedisTemplate redisTemplate;
        
            @Resource
            private RedissonClient redissonClient;
        
            private List<Long> mainUserList = Arrays.asList(1L);
        
            @Scheduled(cron = "0 10 20 * * *")
            public void preCacheUserRecommend(){
                // 获取锁对象
                RLock lock = redissonClient.getLock("friendMatch:precachejob:docache:lock");
        
                try {
                    // 尝试加锁，等待时间0ms，过期时间30000ms。
                    if (lock.tryLock(0, 30000L, TimeUnit.MILLISECONDS)){
                        ValueOperations valueOperations = redisTemplate.opsForValue();
                        String keyTemplate = "friendMatch:user:recommend:%s";
        
                        for (Long aLong : mainUserList) {
                            String key = String.format(keyTemplate, aLong);
                            User user = new User();
                            user.setId(aLong);
                            Page<User> recommendUser = userService.getRecommendUser(user, 1, 8);
        
                            try {
                                valueOperations.set(key, recommendUser, 1, TimeUnit.DAYS);
                            } catch (Exception e) {
                                log.error("redis set key error!!!", e);
                            }
        
                        }
                    }
        
                } catch (Exception e) {
                    log.error("doCacheRecommendUser error", e);
                } finally {
                    // 只能自己释放锁， 且必须注意，释放锁的代码必须写在finally块中，如果在try块，那么上面代码如果报错，则会被catch捕获，导致释放锁的代码不会执行。
                    if (lock.isHeldByCurrentThread()){
                        lock.unlock();
                    }
                }
            }
        
        }
        ```
     
     ### 看门狗机制
     
     现在还有一个分布式锁需要注意的问题没有解决：续期。
     
     Redisson提供了看门狗机制，对于抢占了锁的任务，Redisson会开启一个线程监听该任务，每隔10s，查看任务是否执行完，如果没有，则续期锁到30s。
     
     * 实现方法：
       在lock.tryLock()方法上，将锁释放时间设置为-1.
     
       ```java
       if (lock.tryLock(0, -1, TimeUnit.MILLISECONDS))
       ```
     
     * 注意事项：
       不要使用debug模式去调试自动续锁的看门狗机制，会被认为服务器宕机，不自动续期。
     
     * 面试问题：
     
       1. 为什么看门狗自动续期30s，而不是一个小时或者更久？怕宕机。一旦宕机，锁会被持续占用。
       2. 在Redis分布式集群中，如何向该集群写入锁？？ Redis红锁。具体不深入展开，较高级，需要后面再深入。



# 2025-05-08

## 组队匹配

* 需求分析
  用户能够创建队伍。（在创建过程中，可以指定队伍属性，比如：队伍最大人数，队伍状态[公开，私密,加密]）
  用户能够加入队伍。（对于满员，空闲，不可加入）
  用户能够推出队伍。（如果是队长推出，则顺位传递队长）
  用户能够解散队伍。（只有队长能够解散队伍）
  队长能够修改队伍信息。

-------

### 实现

* 库表设计（5-10min）

队伍表 team

字段：

> id 主键 bigint (使用自增主键， 最简单，连续，放url上比较简短，但缺点是怕爬虫)
>
> name 队伍名称 varchar(128)
>
> description 描述  varchar(1024)
>
> maxNum 最大人数 int
>
> expireTime 过期时间 date
>
> userId 创建者Id bigint
>
> status 状态 int   
>
> password 密码
>
> createTime date
>
> updateTime date
>
> isDelete bool

用户-队伍表

字段:

> id 主键 bigint
>
> userId 用户id bigint
>
> teamId 队伍Id bigint
>
> joinTime 加入时间 date
>
> createTime date
>
> updateTime date
>
> isDelete bool



```sql
create table team
(
    id           bigint auto_increment comment 'id'
        primary key,
    name     varchar(256)                       null comment '队伍名称',
    description     varchar(1024)                      null comment '描述',
    maxNum       tinyint                            null comment '最大人数', 
    expireTime    datetime  null comment '过期时间',
    userId           bigint  comment '用户id',
    status   int      default 0                 not null comment '状态 0 - 公开， 1 - 私密， 2 - 加密',
    password varchar(512)                       null comment '密码',
    createTime   datetime default CURRENT_TIMESTAMP null comment '创建时间',
    updateTime   datetime default CURRENT_TIMESTAMP null on update CURRENT_TIMESTAMP,
    isDelete     tinyint  default 0                 not null comment '是否删除'
)
    comment '队伍';
```

```sql
create table user_team
(
    id           bigint auto_increment comment 'id'
        primary key,
    userId           bigint  comment '用户id',
    teamId           bigint  comment '队伍id',
    joinTime    datetime  comment '加入时间',
    createTime   datetime default CURRENT_TIMESTAMP null comment '创建时间',
    updateTime   datetime default CURRENT_TIMESTAMP null on update CURRENT_TIMESTAMP,
    isDelete     tinyint  default 0                 not null comment '是否删除'
)
    comment '用户队伍关系';
```





两个关系：

1. 用户加入了哪些队伍？
2. 一个队伍有哪些用户？

处理方式：

1. 建立用户-队伍关系表 teamId userId (便于修改，查询性能高一点，可以选择这个，不用全表遍历)

2. 用户表补充已加入队伍字段，队伍表补充已加入用户字段（便于查询，不用写多对多查询代码，可以直接根据用户查队伍，根据队伍查用户）。

   > 经验： 对于多对多关系，如果不用额外的表存储关系，那么就会在这两个表中各添加一个字段。

* 增删改查 （5-10min)



* 业务逻辑开发(10-30min)















